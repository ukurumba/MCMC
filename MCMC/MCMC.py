# -*- coding: utf-8 -*-

def q(fx,i):
	"""This function returns a candidate state given the state that the Markov chain is currently in. 

	Example
	-------
	n = (0,1,2)
	i = 1
	fx(i) = i 
	candidate = q(i,fx)
	print(candidate)


	Parameters
	----------
	i : integer
		The current state of the Markov distribution. 
	fx : function of i
		A function on the current state that computes the candidate state.

	Returns
	-------
	candidate : integer
		candidate is the candidate state based on the decision calculus intrinsic to q."""
	
	q = fx(i)
	return q




def p(eq_distrib,i,j):
	""" This function computes the probability that the candidate state is selected as the new state.

	Examples 
	--------

	i = 1
	j = 2
	eq_distrib = (.2,.3,.3,.1,.1)
	probability = p(i,j,eq_distrib)
	print(probability)

	Parameters
	----------

	eq_distrib: 1-D array
		This is the equilibrium probability distribution for the different possible states in the state space. 

	i : integer
		This is the current state.

	j : integer
		This is the candidate state generated by q.

	Output
	------

	probability : float
		This is the probability that the candidate state j will be selected as the new state."""

	pi_j = eq_distrib[j]
	pi_i = eq_distrib[i]

def next_state(i,j,probability):
	""" This function returns the next state using functions already defined.

	Example
	-------

	state = next_state(2,3,.4)

	Parameters
	----------

	i : integer
		the current state
	
	j : integer
		the candidate state

	probability : float
		the probability that state j is selected

	Output 
	------

	state : integer
		the state chosen"""

def iterator(i,eq_distrib,N):
	"""This is the main body of the implemented algorithm. This ignores the burn-off at the beginning of the simulation.

	Example
	-------
	n = (0,1,2)
	eq_distrib = (.4,.5,.1)
	N = 1000
	i = 2
	X, P = iterator(i,eq_distrib,N)
	print(X)
	print(P)

	Parameters
	----------

	i : integer
		the first state of the particle

	eq_distrib : 1-D array
		the equilibrium probability distribution of the n states in the state space

	N : the number of iterations desired

	Output
	------

	X : array of integers
		the record of all the states the Markov chain took
	P : nxn array of floats
		the transition probability matrix.
		"""

	import numpy as np



